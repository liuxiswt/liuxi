1.redis相关，架构，模式？
(1)主从模式:备份数据 + 负载均衡 
(2)哨兵模式sentinel：在主从模式上，当master节点挂了以后，slave节点不能主动选举一个master节点出来，恢复的master会作为slave节点。
一个sentinel或sentinel集群可以管理多个主从Redis
(3)集群模式cluster：将Redis的数据根据一定的规则分配到多台机器，数据量过大时，可以新增机器进行扩容.可以实现主从和master重选功能.


2.redis为什么快？
    首先，采用了多路复用io阻塞机制
    然后，数据结构简单，操作节省时间
    最后，运行在内存中，自然速度快

3.redis五种数据结构的实现原理？
string(字符串)：SDS 数据类型的定义：字符串存储主要的编码方式主要有两种 ： embstr<44字符 和 raw>44字符
(1)int len 保存了SDS保存字符串的长度
(2)char buf[] 数组用来保存字符串的每个元素
(3)int free j记录了 buf 数组中未使用的字节数量
*其中字符串比较短的时候，len 和 alloc 可以使用 byte 和 short 来表示；为了对内存做极致的优化，不同长度的字符串使用不同的结构体来表示。
* 规定了字符串的长度不得超过 512 MB。
长度的求法：(s-(sizeof(struct sdshdr)))来计算偏移量，sds的指针指向的是char buf[]位置，访问sdshdr的首地址的时候需要减去偏移量。
扩容的方式：字符串长度小于SDS_MAX_PREALLOC (1024*1024)，2倍速度扩容，当字符串长度大于SDS_MAX_PREALLOC，+SDS_MAX_PREALLOC的速度扩容
SDS与C语言的字符串区别：
1)获取字符串长度：C字符串是O(N), SDS是O(1)
2)C字符串strcat函数来进行两个字符串的拼接，一旦没有分配足够长度的内存空间，就会造成缓冲区溢出。SDS 数据类型，在进行字符修改的时候，
会首先根据记录的 len 属性检查内存空间是否满足需求，如果不满足，会进行相应的空间扩展，然后在进行修改操作，所以不会出现缓冲区溢出。
3)C字符串要修改字符串，必须要重新分配内存（先释放再申请).
SDS修改字符串实现了空间预分配和惰性空间释放两种策略：
　　1、空间预分配：对字符串进行空间扩展的时候，扩展的内存比实际需要的多，这样可以减少连续执行字符串增长操作所需的内存重分配次数。
　　2、惰性空间释放：对字符串进行缩短操作时，程序不立即使用内存重新分配来回收缩短后多余的字节，而是使用 free 属性将这些字节的数量记录下来，
  等待后续使用。（当然SDS也提供了相应的API，当我们有需要时，也可以手动释放这些未使用的空间。）
4)C字符串以'\0'作为结束标识，只能报错文本数据。SDS以len 属性表示长度判断结束，可以保存文本或二进制数据。
5)SDS可以使用 C 语言库<string.h> 中的部分函数，C字符串可以使用 C 语言库<string.h> 中的全部函数
list(列表)：
V3.2之前
ziplist:存储上一个 entry的长度和当前entry的长度，加减位移的偏移量实现节点跳跃。存储在连续内存上，存储效率很高；
插入和删除操作需要频繁的申请和释放内存；ziplist长度很长的时候，一次realloc可能会导致大批量的数据拷贝。
linkedlist:维护双指针，插入和删除操作非常快，时间复杂度为 O(1); 但是索引定位很慢，时间复杂度为 O(n)；内存开销大(保存两指针)；
各个节点是单独的内存块，地址不连续，节点多了容易产生内存碎片
V3.2之后
quickList：每一个节点是一个quicklistNode，包含prev和next指针，并包含 一个ziplist，*zp 压缩链表里存储键值
实现阻塞队列：
blpop命令：
redis先找到对应的key的list，如果list不为空则pop一个数据返回给客户端；如果对应的list不存在或者里面没有数据，
就将该key添加到一个blockling_keys的字典中，value就是想订阅该key的client链表
repush命令：
先从blocking_keys中查找是否存在对应的key，如果存在就往ready_keys这个链表中添加该key；同时将value插入到对应的list中，并响应客户端。
*每次处理完客户端命令后都会遍历ready_keys，并通过blocking_keys找到对应的client，依次将对应list的数据pop出来并响应对应的client；
同时检查是否需要再次block。
BIO:一个blpop请求会向redis发起两次I/O请求，一次向redis发送BLPOP key命令，一次从对应的链接管道（channel）中读取数据。
由于BIO的特性当channel中没有数据时会一直阻塞，直到有新数据为止。这样就实现了客户端的阻塞效果


NIO:NIO的特性read和write是两个I/O事件要分别等待selector来触发.如果reqeust和response数据结构里都有带上了requestId，
并且在链接对象上缓存了requestId和响应future的对应关系，因此链接可以不用独享
hash(字典)：哈希表(数组+链表) * 2
通常情况下只有一个 hashtable 是有值的，但是在字典扩容缩容时，需要分配新的 hashtable，然后进行渐进式搬迁：
rehash:
大字典的扩容是比较耗时间的，需要重新申请新的数组，然后将旧字典所有链表中的元素重新挂接到新的数组下面，这是一个 O(n)操作。 
redis根据 0 号哈希表的已有节点来计算需要扩展的大小，根据该大小创建 1 号哈希表，再把 0 号哈希表的数据慢慢移动到 1 号哈希表上，
rehash 指的是重新计算键的哈希值和索引值， 然后将键值对放置到 ht[1] 哈希表的指定位置上。当移到完成后，再把 1 号哈希表赋给 0 号哈希表，
之后清空 1 号哈希表，为下次 rehash 做准备。
扩容机制：初始大小4. 正常情况下，元素的个数等于第一维数组的长度时，扩容的新数组是 原数组大小的 2 倍；在做bgsave(持久化)时，
节点是表大小的5倍以上时，强制扩容节点*2；
扩缩机制：元素个数低于数组长度的 10%(缩容不会考虑 Redis 是否在做 bgsave）
set(集合) ：相当于 Java 语言中的 HashSet，它内部的键值对是无序、唯一的。它的内部实现相当于一个特殊的字典，字典中所有的 value 都是一个值 NULL。
zset(有序集合)：元素小于128，元素的长度都小于64字节使用ziplist(第一个节点保存数据，第二节点保存score，查询O(n))，否则skiplist
skiplist：字典+ 跳跃表(插入、删除、查找的复杂度均为O(logN))
跳跃表：多层的链表，每一层链表的节点个数大约是下面一层的节点个数的一半，为了方便插入，不要求上下相邻两层链表之间的节点个数有严格的对应关系，
而是为每个节点随机出一个层数(level)。插入时，使用这个层数，不影响其他节点。
均匀分布的随机层数实现：
1）首先，每个节点肯定都有第1层指针（每个节点都在第1层链表里）。
2）如果一个节点有第i层(i>=1)指针（即节点已经在第1层到第i层链表中），那么它有第(i+1)层指针的概率为p。
3）节点最大的层数不允许超过一个最大值，记为MaxLevel。
randomLevel()
level := 1
// random()返回一个[0...1)的随机数
while random() < p and level < MaxLevel do
level := level + 1
return level
其中
p = 1/4
MaxLevel = 32(层数)
直观上期望的目标是1/2概率被分配上上一级。即 50% 的概率被分配到 Level 1，25% 的概率被分配到 Level 2，12.5% 的概率被分配到 Level 3...
Redis使用跳表特殊点：
 分数(score)允许重复，即skiplist的key允许重复。这在最开始介绍的经典skiplist中是不允许的。
 在比较时，不仅比较分数（相当于skiplist的key），还比较数据本身。在Redis的skiplist实现中，数据本身的内容唯一标识这份数据，而不是由key来唯一标识。
 另外，当多个元素分数相同的时候，还需要根据数据内容来进字典排序。
 第1层链表不是一个单向链表，而是一个双向链表。这是为了方便以倒序方式获取一个范围内的元素。
 在skiplist中可以很方便地计算出每个元素的排名(rank)。


4.bigkey危害和处理？
string类型控制在10KB以内，hash、list、set、zset元素个数不要超过5000。
危害：
1).内存空间不均匀(集群不易管理，数据丢失) 
2).超时阻塞(查询时bigkey耗时大)
3).网络拥塞(占用带宽)
4.) 过期删除(没有使用Redis 4.0的过期异步删除(lazyfree-lazy-expire yes)，就会存在阻塞Redis的可能性,并且是内部循环事件，
可以从latency命令中获取或者从slave节点慢查询发现）。)
5). 迁移困难(migrate实际上是通过dump + restore + del三个命令组合成原子命令完成，如果是bigkey，可能会使迁移失败，而且较慢的migrate会阻塞Redis)
发现：
1). redis-cli --bigkeys
2). debug object ${key}
3).(V4.0之后) memory usage
4).客户端,做判断长度，收集日志
删除：
1）String：del
2）hash: hscan获取部分，hdel删除
3）list: ltrim渐进获取，在del
4)  set: sscan获取部分,srem删除
5）zset: zscan获取部分,zremrangebyrank删除
优化：list拆分，二次hash, 减少本地缓存(涉及到序列化，增大bigkey开销)等


5.redis用跳表不用平衡二叉树？
1) 也不是非常耗费内存，实际上取决于生成层数函数里的概率 p，取决得当的话其实和平衡树差不多。
2) 因为有序集合经常会进行 ZRANGE 或 ZREVRANGE 这样的范围查找操作，跳表里面的双向链表可以十分方便地进行这类操作。
3) 实现简单，ZRANK 操作还能达到 o(logn)的时间复杂度O



6.基数统计(统计一个集合中不重复的元素个数)的常用方法？
1）B 树：最大的优势就是插入和查找效率很高。快速判断新来的数据是否存在，并快速将元素插入 B 树。要计算基础值，只需要计算 B 树的节点个数。并没有节省内存
2）bitmap: 不存在是0，存在是1.节省内存。设定全量bitmap,用异或操作，替代"非"操作；
3) EWAHCompressedBitmap(优化bitmap):将整个（未经过任何压缩的）bitmap每64位拆分为一个最小单元;初始化4个word
word{
Buffer buffer；Long[]或者LongBufferWrapper(NIO)
int position；始终指向整个Buffer中最后一个run-length,避免重头查询，路标
}
当 64位全都是相同0或1时，称为RLW,会进行压处理（即为跨度信息，低32表示跨度，搞32位表示当前节点后方有多少个连续的lw）、
当64位即有0又有1时，称为LW，直接存储数据。
推荐从小到大存储数据，不然会使RLW分裂，影响性能。
4）redis的HyperLogLog(概率估算) 原理： 16384 个桶，即：214，也就是说，Redis 最大能够统计的数据量是 264，
即每个桶的 maxbit 需要 6 个 bit 来存储，最大可以表示 maxbit = 63，于是总共占用内存就是：(214) x 6 / 8 (每个桶 6 bit，
而这么多桶本身要占用 16384 bit，再除以 8 转换成 KB),算出来的结果就是 12 KB
当稀疏存储的某个计数值需要调整到大于 32 时，Redis 就会立即转换 HyperLogLog 的存储结构，将稀疏存储转换成密集存储。


7.简述Redis的数据淘汰机制
    volatile-lru 从已设置过期时间的数据集中挑选最近最少使用的数据淘汰
    volatile-ttl 从已设置过期时间的数据集中挑选将要过期的数据淘汰
    volatile-random从已设置过期时间的数据集中任意选择数据淘汰
    allkeys-lru从所有数据集中挑选最近最少使用的数据淘汰
    allkeys-random从所有数据集中任意选择数据进行淘汰
    noeviction禁止驱逐数据
    
 8.缓存穿透、缓存击穿、缓存雪崩？
 缓存穿透：就是客户持续向服务器发起对不存在服务器中数据的请求。客户先在Redis中查询，查询不到后去数据库中查询。
    1).接口层增加校验，对传参进行个校验，比如说我们的id是从1开始的，那么id<=0的直接拦截；
    2).缓存中取不到的数据，在数据库中也没有取到，这时可以将key-value对写为key-null，这样可以防止攻击用户反复用同一个id暴力攻击
 缓存击穿：就是一个很热门的数据，突然失效，大量请求到服务器数据库中
    1).最好的办法就是设置热点数据永不过期
 缓存雪崩：就是大量数据同一时间失效。
    1).缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。
    2).如果缓存数据库是分布式部署，将热点数据均匀分布在不同搞得缓存数据库中。
   
    
   
