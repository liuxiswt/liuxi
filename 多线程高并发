1.如何控制多线程的执行顺序？
方法一：使用join()方法让一个线程强制运行(原理：让子线程强制运行，阻塞了主线程的运行)
方法二：使用juc包下的Executors线程池 创建单线程的newSingleThreadExecutor(原理：基于FIFO（先进先出）的队列)
方法三：CountDownLatch(原理：检测到计数器为0当前线程就可以往下执行)
方法四：java8 CompletableFuture   的API，thenAccept(上结下参，无返回)/thenRun(不管上，执行下，无返回)/thenApply(上结下参，有返回)

2.乐观锁和悲观锁
乐观锁：读数据不会上锁，更新时判断是否已被更新。用于多读的应用类型，提高吞吐量。实现：版本号机制或CAS算法 缺陷：ABA问题
悲观锁：共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程。实现：synchronized、ReentrantLock
版本号：数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。
CAS:拿期望的值和原本的一个值作比较，如果相同则更新成新的值.不同就一直循环执行直到成功(自旋锁) 

3.原子类：原理：volatile  + CAS
基本类型：AtomicInteger：整形原子类AtomicLong：长整型原子类AtomicBoolean：布尔型原子类
数组类型：AtomicIntegerArray：整形数组原子类AtomicLongArray：长整形数组原子类AtomicReferenceArray：引用类型数组原子类
引用类型：AtomicReference：引用类型原子类AtomicStampedReference：原子更新引用类型里的字段原子类AtomicMarkableReference ：原子更新带有标记位的引用类型
对象的属性修改类型：AtomicIntegerFieldUpdater：原子更新整形字段的更新器AtomicLongFieldUpdater：原子更新长整形字段的更新器AtomicStampedReference：原子更新带有版本号的引用类型


4.并发容器：
ConcurrentHashMap 数据分为一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据时，其他段的数据也能被其他线程访问。
CopyOnWriteArrayList 类的所有可变操作（add，set 等等）都是通过创建底层数组的新副本来实现的。当 List 需要被修改的时候，我并不修改原有内容，而是对原有数据进行一次复制，将修改的内容写入副本。写完之后，再将修改完的副本替换原来的数据，这样就可以保证写操作不会影响读操作了。
ConcurrentLinkedQueue 主要使用 CAS 非阻塞算法来实现线程安全
ArrayBlockingQueue 是 BlockingQueue 接口的有界队列实现类，底层采用数组来实现。ArrayBlockingQueue 一旦创建，容量不能改变。其并发控制采用可重入锁来控制，不管是插入操作还是读取操作，都需要获取到锁才能进行操作。当队列容量满时，尝试将元素放入队列将导致操作阻塞;尝试从一个空队列中取一个元素也会同样阻塞。
LinkedBlockingQueue 底层基于单向链表实现的阻塞队列，可以当做无界队列也可以当做有界队列来使用，同样满足 FIFO 的特性，与 ArrayBlockingQueue 相比起来具有更高的吞吐量，为了防止 LinkedBlockingQueue 容量迅速增，损耗大量内存。通常在创建 LinkedBlockingQueue 对象时，会指定其大小，如果未指定，容量等于 Integer.MAX_VALUE。
PriorityBlockingQueue 一个支持优先级的无界阻塞队列。并发控制采用的是 ReentrantLock，队列为无界队列（ArrayBlockingQueue 是有界队列，LinkedBlockingQueue 也可以通过在构造函数中传入 capacity 指定队列最大的容量，但是 PriorityBlockingQueue 只能指定初始的队列大小，后面插入元素的时候，如果空间不够的话会自动扩容）。

5.synchronized(JVM实现 monitorenter 和 monitorexit 指令)(非公平锁) 原子性。
修饰实例方法(对象实例加锁)、静态方法(当前类加锁)、代码块(给定对象加锁)
和ReentrantLock 的区别： 两者都是可重入锁、ReentrantLock通过lock,unlock实现、ReentrantLock高级功能:①等待可中断；②可实现公平锁；③可实现选择性通知Condition灵活（锁可以绑定多个条件）
volatile(通知JVM不从本地，从主存中读取):性能优于synchronized，非阻塞性，只用于变量，数据的可见性、有序性。

6.ThreadLocal当前线程的专属本地值。ThreadLocalMap 是弱引用。 不remove()可能造成内存泄漏。

7.Runnable(不会返回结果或抛出检查异常)和Callable(可以返回结果或抛出异常) 

8.线程池 作用：降低资源消耗、提高响应速度、提高线程的可管理性 execute()提交没有返回值 submit()提交有返回值的。Future接收线程返回的结果，get()为阻塞方法。

9.ThreadPoolExecutor参数： corePoolSize核心(最小)线程数 maximumPoolSize：最大线程数  workQueue:判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列； keepAliveTime最大等待时间；unit 等待时间的单位；
handler 饱和策略：
ThreadPoolExecutor.AbortPolicy：抛出 RejectedExecutionException来拒绝新任务的处理。
ThreadPoolExecutor.CallerRunsPolicy：调用执行自己的线程运行任务。您不会任务请求。但是这种策略会降低对于新任务提交速度，影响程序的整体性能。另外，这个策略喜欢增加队列容量。如果您的应用程序可以承受此延迟并且你不能任务丢弃任何一个任务请求的话，你可以选择这个策略。
ThreadPoolExecutor.DiscardPolicy： 不处理新任务，直接丢弃掉。
ThreadPoolExecutor.DiscardOldestPolicy： 此策略将丢弃最早的未处理的任务请求。

10.AQS是一个用来构建锁和同步器的框架(定义两种资源共享方式：Exclusive独占/ Share共享)，使用模板方法模式.使用AQS能简单且高效地构造出应用广泛的大量的同步器.
AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。
CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点（Node）来实现锁的分配。

11. sleep() 方法和 wait() 方法区别和共同点?
两者最主要的区别在于：sleep 方法没有释放锁，而 wait 方法释放了锁 。
两者都可以暂停线程的执行。
Wait 通常被用于线程间交互/通信，sleep 通常被用于暂停执行。
wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify() 或者 notifyAll() 方法。sleep() 方法执行完成后，线程会自动苏醒。或者可以使用 wait(long timeout)超时后线程会自动苏醒。

12.线程生命周期：初始、运行、阻塞、等待、超时等待、终止 。调用 start 方法方可启动线程并使线程进入就绪状态，而 run 方法只是 thread 的一个普通方法调用，还是在主线程里执行。
